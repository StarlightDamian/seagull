

1.超过沪深300 1%

2.放量上涨

放量下跌

缩量上涨

缩量下跌



3.卡玛比



数据预处理：



自动标签编码

训练测试集划分

支持自定义特征选择





模型训练：



可配置的LightGBM参数

支持早停

验证集评估

交叉验证





模型评估：



准确率评估

分类报告

混淆矩阵可视化

特征重要性分析





预测功能：



类别预测

概率预测





可视化：



特征重要性图

混淆矩阵热力图







使用建议：



参数调优：



使用网格搜索或贝叶斯优化调整参数

根据数据规模调整num_leaves和max_depth

注意过拟合问题





特征工程：



添加特征选择

处理缺失值和异常值

特征标准化/归一化





模型解释：



分析特征重要性

观察混淆矩阵

关注分类错误的样本





实际应用：



保存和加载模型

模型部署考虑

定期重训练

"""



import numpy as np

import pandas as pd

import lightgbm as lgb

from sklearn.model_selection import train_test_split, StratifiedKFold

from sklearn.preprocessing import LabelEncoder

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

import matplotlib.pyplot as plt

import seaborn as sns

from typing import Tuple, Dict, List



class LightGBMClassifier:

​    """LightGBM三分类模型封装"""

​    

​    def __init__(self, params: Dict = None):

​        """

​        初始化分类器

​        

​        Args:

​            params: LightGBM参数字典

​        """

​        self.params = params or {

​            'objective': 'multiclass',

​            'num_class': 3,

​            'metric': 'multi_logloss',

​            'boosting_type': 'gbdt',

​            'learning_rate': 0.05,

​            'num_leaves': 31,

​            'min_data_in_leaf': 20,

​            'max_depth': -1,

​            'bagging_fraction': 0.8,

​            'feature_fraction': 0.8,

​            'bagging_freq': 5,

​            'verbose': -1,

​            'random_state': 42

​        }

​        self.model = None

​        self.feature_importance = None

​        

​    def prepare_data(

​        self, 

​        data: pd.DataFrame,

​        target_col: str,

​        features: List[str] = None,

​        test_size: float = 0.2

​    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:

​        """

​        准备训练和测试数据

​        

​        Args:

​            data: 输入数据DataFrame

​            target_col: 目标列名

​            features: 特征列名列表

​            test_size: 测试集比例

​            

​        Returns:

​            训练特征, 测试特征, 训练标签, 测试标签

​        """

​        \# 如果未指定特征，使用除目标列外的所有列

​        if features is None:

​            features = [col for col in data.columns if col != target_col]

​            

​        X = data[features]

​        y = data[target_col]

​        

​        \# 标签编码

​        le = LabelEncoder()

​        y = le.fit_transform(y)

​        

​        \# 划分训练测试集

​        return train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)

​    

​    def train(

​        self,

​        X_train: pd.DataFrame,

​        y_train: pd.Series,

​        X_val: pd.DataFrame = None,

​        y_val: pd.Series = None,

​        num_boost_round: int = 1000,

​        early_stopping_rounds: int = 50

​    ):

​        """

​        训练模型

​        

​        Args:

​            X_train: 训练特征

​            y_train: 训练标签

​            X_val: 验证特征

​            y_val: 验证标签

​            num_boost_round: 最大迭代次数

​            early_stopping_rounds: 早停轮数

​        """

​        \# 创建数据集

​        train_data = lgb.Dataset(X_train, label=y_train)

​        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data) if X_val is not None else None

​        

​        \# 训练模型

​        self.model = lgb.train(

​            self.params,

​            train_data,

​            num_boost_round=num_boost_round,

​            valid_sets=[val_data] if val_data else None,

​            early_stopping_rounds=early_stopping_rounds

​        )

​        

​        \# 记录特征重要性

​        self.feature_importance = pd.DataFrame({

​            'feature': X_train.columns,

​            'importance': self.model.feature_importance('gain')

​        }).sort_values('importance', ascending=False)

​        

​    def predict(self, X: pd.DataFrame) -> np.ndarray:

​        """

​        预测类别

​        

​        Args:

​            X: 预测特征

​            

​        Returns:

​            预测类别

​        """

​        return self.model.predict(X).argmax(axis=1)

​    

​    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:

​        """

​        预测概率

​        

​        Args:

​            X: 预测特征

​            

​        Returns:

​            预测概率

​        """

​        return self.model.predict(X)

​    

​    def cross_validate(

​        self,

​        X: pd.DataFrame,

​        y: pd.Series,

​        n_splits: int = 5

​    ) -> Tuple[float, float]:

​        """

​        交叉验证

​        

​        Args:

​            X: 特征

​            y: 标签

​            n_splits: 折数

​            

​        Returns:

​            平均准确率, 标准差

​        """

​        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

​        scores = []

​        

​        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):

​            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]

​            y_train, y_val = y[train_idx], y[val_idx]

​            

​            self.train(X_train, y_train, X_val, y_val)

​            y_pred = self.predict(X_val)

​            score = accuracy_score(y_val, y_pred)

​            scores.append(score)

​            

​        return np.mean(scores), np.std(scores)

​    

​    def plot_feature_importance(self, top_n: int = 20):

​        """

​        绘制特征重要性图

​        

​        Args:

​            top_n: 展示前n个重要特征

​        """

​        plt.figure(figsize=(10, 6))

​        data = self.feature_importance.head(top_n)

​        sns.barplot(x='importance', y='feature', data=data)

​        plt.title(f'Top {top_n} Feature Importance')

​        plt.show()

​    

​    def plot_confusion_matrix(self, y_true: np.ndarray, y_pred: np.ndarray):

​        """

​        绘制混淆矩阵

​        

​        Args:

​            y_true: 真实标签

​            y_pred: 预测标签

​        """

​        cm = confusion_matrix(y_true, y_pred)

​        plt.figure(figsize=(8, 6))

​        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

​        plt.title('Confusion Matrix')

​        plt.xlabel('Predicted')

​        plt.ylabel('True')

​        plt.show()



def main():

​    """示例用法"""

​    \# 生成示例数据

​    np.random.seed(42)

​    n_samples = 1000

​    

​    \# 创建特征

​    X = pd.DataFrame({

​        f'feature_{i}': np.random.normal(0, 1, n_samples) 

​        for i in range(10)

​    })

​    

​    \# 创建标签 (三分类)

​    y = pd.Series(np.random.choice([0, 1, 2], size=n_samples))

​    

​    \# 初始化分类器

​    classifier = LightGBMClassifier()

​    

​    \# 准备数据

​    X_train, X_test, y_train, y_test = classifier.prepare_data(

​        pd.concat([X, y.to_frame('target')], axis=1),

​        'target'

​    )

​    

​    \# 训练模型

​    classifier.train(X_train, y_train, X_test, y_test)

​    

​    \# 预测

​    y_pred = classifier.predict(X_test)

​    

​    \# 输出评估报告

​    print("\nClassification Report:")

​    print(classification_report(y_test, y_pred))

​    

​    \# 交叉验证

​    mean_score, std_score = classifier.cross_validate(X, y)

​    print(f"\nCross Validation Score: {mean_score:.4f} (+/- {std_score:.4f})")

​    

​    \# 绘制特征重要性

​    classifier.plot_feature_importance()

​    

​    \# 绘制混淆矩阵

​    classifier.plot_confusion_matrix(y_test, y_pred)



if __name__ == "__main__":

​    main()